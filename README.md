# 🔢 Numerical Analysis

A comprehensive collection of Python implementations for various numerical analysis methods and algorithms.

## 📋 Table of Contents

1. [Features](#-features)
2. [Technology Stack](#-technology-stack)
3. [Installation](#-installation)
4. [Project Structure](#-project-structure)
5. [Lab Implementations](#-lab-implementations)
6. [Contributing](#-contributing)
7. [Contact](#-contact)

---

## ✨ Features

- **Number System Conversion**: Convert numbers between different bases (2-36)
- **Iterative Methods**: Implementation of Jacobi, Gauss-Seidel, and Relaxation methods
- **Interpolation Methods**: 
  - Lagrange Interpolation
  - Newton's Forward/Backward Difference
  - Newton's Divided Difference
- **Regression Methods**: Linear and Power Fit Regression
- **Numerical Differentiation**: Higher-order differentiation with Richardson Extrapolation
- **Numerical Integration**: 
  - Trapezoidal Rule
  - Simpson's 1/3 Rule
  - Simpson's 3/8 Rule
  - Romberg Integration

---

## 🛠️ Technology Stack

- **Python 3.x**: Core programming language
- **Built-in Libraries**: NumPy for numerical computations
- **Type Hints**: Modern Python type annotations for better code clarity

---

## 📦 Installation

1. **Clone the Repository**

```bash
git clone https://github.com/sahithi-sss/Numerical-Optimization
cd Numerical-Optimization
```

2. **Install Dependencies**

```bash
pip install numpy
```

---

## 📁 Project Structure

```plaintext
NA Lab/
│
├── number_sys_conversion/
│   └── number_sys_conv.py
│
├── lab6/
│   └── NA_Lab6.pdf
│
├── Iterative_mtds_for_Multivariate_eqns/
│   ├── jacobi_iteration_mtd.py
│   ├── gauss_seidel_mtd.py
│   ├── mtd_of_relaxation.py
│   └── NA_Lab7.pdf
│
├── Lagrange_interpolation_mtd/
│   ├── lagrange_interpolation.py
│   ├── newtons_divided_diff.py
│   └── NA_Lab8.pdf
│
├── Netwon_interpolation_mtds_1/
│   ├── newtons_fwd_diff.py
│   ├── newtons_backwd_diff.py
│   └── NA_Lab9.pdf
│
├── Newton_interpolation_mtds_2/
│   ├── newton_fwd_backwd_interpolation.py
│   └── NA_Lab10.pdf
│
├── Regression_mtds/
│   ├── regression.py
│   ├── powerfit_regression.py
│   └── lab 11.pdf
│
├── Higher_order_differentiation/
│   ├── higher_order_diff.py
│   ├── richardson_extrapolation_Q1.py
│   └── NA_Lab12.pdf
│
├── Integration_mtds/
│   ├── trapezoidal_rule.py
│   ├── simpson1-3_rule.py
│   ├── simpson3-8_rule.py
│   ├── romberg_trap.py
│   └── NA_Lab13.pdf
│
├── Questions/
│   └── [Lab Question PDFs]
│
└── README.md
```

---

## 📝 Lab Implementations

### 1. Number System Conversion
- Base conversion between 2-36
- Support for fractional numbers
- High precision calculations

### 2. Iterative Methods for Multivariate Equations
- Jacobi Iteration Method
- Gauss-Seidel Method
- Method of Relaxation

### 3. Interpolation Methods
- Lagrange Interpolation
- Newton's Forward Difference
- Newton's Backward Difference
- Newton's Divided Difference

### 4. Regression Methods
- Linear Regression
- Power Fit Regression

### 5. Numerical Differentiation
- Higher-order Differentiation
- Richardson Extrapolation

### 6. Numerical Integration
- Trapezoidal Rule
- Simpson's 1/3 Rule
- Simpson's 3/8 Rule
- Romberg Integration

---

## 🤝 Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a new branch (`git checkout -b feature-branch`)
3. Make your changes
4. Commit your changes (`git commit -m 'Add new feature'`)
5. Push to the branch (`git push origin feature-branch`)
6. Create a Pull Request

---

## 📧 Contact

[Sri Sahithi Sunkaranam]  
[https://github.com/sahithi-sss] | [ssrisahthis@gmail.com]

---

> This project is designed for educational purposes, implementing various numerical analysis methods and algorithms in Python. Each implementation includes detailed documentation and examples. 
